{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7534cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: download in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (0.3.5)\n",
      "Requirement already satisfied: tqdm in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from download) (4.64.1)\n",
      "Requirement already satisfied: six in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from download) (1.16.0)\n",
      "Requirement already satisfied: requests in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from download) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from requests->download) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from requests->download) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from requests->download) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from requests->download) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5538801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataset in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from dataset) (1.4.39)\n",
      "Requirement already satisfied: alembic>=0.6.2 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from dataset) (1.11.1)\n",
      "Requirement already satisfied: banal>=1.0.1 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from dataset) (1.0.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from alembic>=0.6.2->dataset) (4.3.0)\n",
      "Requirement already satisfied: Mako in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from alembic>=0.6.2->dataset) (1.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/vikrantmehla/opt/anaconda3/lib/python3.9/site-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b253880",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Functions for downloading the CIFAR-10 data-set from the internet\n",
    "# and loading it into memory.\n",
    "#\n",
    "# Implemented in Python 3.5\n",
    "#\n",
    "# Usage:\n",
    "# 1) Set the variable data_path with the desired storage path.\n",
    "# 2) Call maybe_download_and_extract() to download the data-set\n",
    "#    if it is not already located in the given data_path.\n",
    "# 3) Call load_class_names() to get an array of the class-names.\n",
    "# 4) Call load_training_data() and load_test_data() to get\n",
    "#    the images, class-numbers and one-hot encoded class-labels\n",
    "#    for the training-set and test-set.\n",
    "# 5) Use the returned data in your own program.\n",
    "#\n",
    "# Format:\n",
    "# The images for the training- and test-sets are returned as 4-dim numpy\n",
    "# arrays each with the shape: [image_number, height, width, channel]\n",
    "# where the individual pixels are floats between 0.0 and 1.0.\n",
    "#\n",
    "########################################################################\n",
    "#\n",
    "# This file is part of the TensorFlow Tutorials available at:\n",
    "#\n",
    "# https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "#\n",
    "# Published under the MIT License. See the file LICENSE for details.\n",
    "#\n",
    "# Copyright 2016 by Magnus Erik Hvass Pedersen\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import download\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# Directory where you want to download and save the data-set.\n",
    "# Set this before you start calling any of the functions below.\n",
    "data_path = \"/Users/vikrantmehla/Cifar_Dataset\"\n",
    "\n",
    "# URL for the data-set on the internet.\n",
    "data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "\n",
    "########################################################################\n",
    "# Various constants for the size of the images.\n",
    "# Use these constants in your own program.\n",
    "\n",
    "# Width and height of each image.\n",
    "img_size = 32\n",
    "\n",
    "# Number of channels in each image, 3 channels: Red, Green, Blue.\n",
    "num_channels = 3\n",
    "\n",
    "# Length of an image when flattened to a 1-dim array.\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 10\n",
    "\n",
    "########################################################################\n",
    "# Various constants used to allocate arrays of the correct size.\n",
    "\n",
    "# Number of files for the training-set.\n",
    "_num_files_train = 5\n",
    "\n",
    "# Number of images for each batch-file in the training-set.\n",
    "_images_per_file = 10000\n",
    "\n",
    "# Total number of images in the training-set.\n",
    "# This is used to pre-allocate arrays for efficiency.\n",
    "_num_images_train = _num_files_train * _images_per_file\n",
    "\n",
    "########################################################################\n",
    "# Private functions for downloading, unpacking and loading data-files.\n",
    "\n",
    "\n",
    "def _get_file_path(filename=\"\"):\n",
    "    \"\"\"\n",
    "    Return the full path of a data-file for the data-set.\n",
    "\n",
    "    If filename==\"\" then return the directory of the files.\n",
    "    \"\"\"\n",
    "\n",
    "    return os.path.join(data_path, \"cifar-10-batches-py/\", filename)\n",
    "\n",
    "\n",
    "def _unpickle(filename):\n",
    "    \"\"\"\n",
    "    Unpickle the given file and return the data.\n",
    "\n",
    "    Note that the appropriate dir-name is prepended the filename.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create full path for the file.\n",
    "    file_path = _get_file_path(filename)\n",
    "\n",
    "    print(\"Loading data: \" + file_path)\n",
    "\n",
    "    with open(file_path, mode='rb') as file:\n",
    "        # In Python 3.X it is important to set the encoding,\n",
    "        # otherwise an exception is raised here.\n",
    "        data = pickle.load(file,  encoding='latin1')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _convert_images(raw):\n",
    "    \"\"\"\n",
    "    Convert images from the CIFAR-10 format and\n",
    "    return a 4-dim array with shape: [image_number, height, width, channel]\n",
    "    where the pixels are floats between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the raw images from the data-files to floating-points.\n",
    "    raw_float = np.array(raw, dtype=float) / 255.0\n",
    "\n",
    "    # Reshape the array to 4-dimensions.\n",
    "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
    "\n",
    "    # Reorder the indices of the array.\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def _load_data(filename):\n",
    "    \"\"\"\n",
    "    Load a pickled data-file from the CIFAR-10 data-set\n",
    "    and return the converted images (see above) and the class-number\n",
    "    for each image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pickled data-file.\n",
    "    data = _unpickle(filename)\n",
    "\n",
    "    # Get the raw images.\n",
    "    raw_images = data['data']\n",
    "\n",
    "    # Get the class-numbers for each image. Convert to numpy-array.\n",
    "    cls = np.array(data['labels'])\n",
    "\n",
    "    # Convert the images.\n",
    "    images = _convert_images(raw_images)\n",
    "\n",
    "    return images, cls\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Public functions that you may call to download the data-set from\n",
    "# the internet and load the data into memory.\n",
    "\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the CIFAR-10 data-set if it doesn't already exist\n",
    "    in data_path (set this variable first to the desired path).\n",
    "    \"\"\"\n",
    "\n",
    "    download.maybe_download_and_extract(url=data_url, download_dir=data_path)\n",
    "\n",
    "\n",
    "def load_class_names():\n",
    "    \"\"\"\n",
    "    Load the names for the classes in the CIFAR-10 data-set.\n",
    "\n",
    "    Returns a list with the names. Example: names[3] is the name\n",
    "    associated with class-number 3.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the class-names from the pickled file.\n",
    "    raw = _unpickle(filename=\"batches.meta\")['label_names']\n",
    "\n",
    "    # Convert from binary strings.\n",
    "    return raw\n",
    "\n",
    "\n",
    "def load_training_data():\n",
    "    \"\"\"\n",
    "    Load all the training-data for the CIFAR-10 data-set.\n",
    "\n",
    "    The data-set is split into 5 data-files which are merged here.\n",
    "\n",
    "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
    "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
    "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
    "\n",
    "    # Begin-index for the current batch.\n",
    "    begin = 0\n",
    "\n",
    "    # For each data-file.\n",
    "    for i in range(_num_files_train):\n",
    "        # Load the images and class-numbers from the data-file.\n",
    "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
    "\n",
    "        # Number of images in this batch.\n",
    "        num_images = len(images_batch)\n",
    "\n",
    "        # End-index for the current batch.\n",
    "        end = begin + num_images\n",
    "\n",
    "        # Store the images into the array.\n",
    "        images[begin:end, :] = images_batch\n",
    "\n",
    "        # Store the class-numbers into the array.\n",
    "        cls[begin:end] = cls_batch\n",
    "\n",
    "        # The begin-index for the next batch is the current end-index.\n",
    "        begin = end\n",
    "\n",
    "    return images, cls, OneHotEncoder(class_numbers=cls, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Load all the test-data for the CIFAR-10 data-set.\n",
    "\n",
    "    Returns the images, class-numbers and one-hot encoded class-labels.\n",
    "    \"\"\"\n",
    "\n",
    "    images, cls = _load_data(filename=\"test_batch\")\n",
    "\n",
    "    return images, cls, OneHotEncoder(class_numbers=cls, num_classes=num_classes)\n",
    "\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10a6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbda16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
